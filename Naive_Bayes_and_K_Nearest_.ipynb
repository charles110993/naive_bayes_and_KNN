{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Nytsiy2g4yWx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    # Perform any necessary preprocessing steps\n",
        "    # For example, handle missing values, convert categorical variables, etc.\n",
        "    # This function should return the preprocessed data\n",
        "    # Example: Data normalization\n",
        "    data_normalized = (data - data.min()) / (data.max() - data.min())\n",
        "    return data_normalized\n"
      ],
      "metadata": {
        "id": "YNUN_MjsMp9R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(x, y, test_size=0.2):\n",
        "    # Split the data into training and testing sets\n",
        "    # The 'test_size' parameter determines the ratio of testing data\n",
        "    # This function should return the training and testing sets\n",
        "    # Example: Random shuffle and split\n",
        "    np.random.seed(42)\n",
        "    shuffled_indices = np.random.permutation(len(x))\n",
        "    test_set_size = int(len(x) * test_size)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    x_train = x[train_indices]\n",
        "    x_test = x[test_indices]\n",
        "    y_train = y[train_indices]\n",
        "    y_test = y[test_indices]\n",
        "    return x_train, x_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "KKX1XkO6MtUD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_prior_probabilities(y_train):\n",
        "    # Calculate the prior probabilities for each class in the training data\n",
        "    # This function should return a dictionary with class labels as keys and corresponding probabilities as values\n",
        "    class_labels, class_counts = np.unique(y_train, return_counts=True)\n",
        "    prior_probabilities = {}\n",
        "    total_samples = len(y_train)\n",
        "    for label, count in zip(class_labels, class_counts):\n",
        "        prior_probabilities[label] = count / total_samples\n",
        "    return prior_probabilities"
      ],
      "metadata": {
        "id": "5eMt9AbeMw0E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_likelihoods(x_train, y_train):\n",
        "    # Calculate the likelihoods for each feature and class combination in the training data\n",
        "    # This function should return a dictionary with class labels as keys and dictionaries of feature likelihoods as values\n",
        "    class_labels = np.unique(y_train)\n",
        "    likelihoods = {}\n",
        "    for label in class_labels:\n",
        "        label_indices = np.where(y_train == label)\n",
        "        label_data = x_train[label_indices]\n",
        "        likelihoods[label] = {\n",
        "            'mean': np.mean(label_data, axis=0),\n",
        "            'std': np.std(label_data, axis=0)\n",
        "        }\n",
        "    return likelihoods"
      ],
      "metadata": {
        "id": "eBxTuzVZM078"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V_hwwC7bNLB9"
      },
      "outputs": [],
      "source": [
        "def predict_naive_bayes(x_test, prior_probabilities, likelihoods):\n",
        "    # Predict the class labels for the test data using Naive Bayes algorithm\n",
        "    # This function should return the predicted class labels\n",
        "    predictions = []\n",
        "    for sample in x_test:\n",
        "        posteriors = {}\n",
        "        for label, likelihood in likelihoods.items():\n",
        "            prior = prior_probabilities[label]\n",
        "            class_likelihood = np.prod(\n",
        "                (1 / (np.sqrt(2 * np.pi) * likelihood['std'])) *\n",
        "                np.exp(-((sample - likelihood['mean']) ** 2) / (2 * likelihood['std'] ** 2))\n",
        "            )\n",
        "            posterior = prior * class_likelihood\n",
        "            posteriors[label] = posterior\n",
        "        predicted_label = max(posteriors, key=posteriors.get)\n",
        "        predictions.append(predicted_label)\n",
        "   \n"
      ]
    }
  ]
}